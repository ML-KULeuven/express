{
 "cells": [
  {
   "cell_type": "code",
   "id": "95c86dae6b2c3790",
   "metadata": {},
   "source": [
    "# Import required libraries and utility functions for the experiment\n",
    "import pandas as pd\n",
    "import json\n",
    "from utils.constants import OBJECTIVES_SUDOKU\n",
    "from utils.utils import load_sudokus_from_json, create_folders\n",
    "from utils.utils_classes import Oracle\n",
    "from utils.utils_training import PreferenceElicitationFramework\n",
    "from utils.utils_classes import Human\n",
    "from utils.utils_sudoku import generate_steps_sudoku\n",
    "import ast\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils.utils import count_and_remove_matching_hints"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "85b5d64bd5192c2f",
   "metadata": {},
   "source": [
    "# Set experiment parameters: learning rate, normalization type, and step selection strategy\n",
    "lr = 1\n",
    "normalization = 2\n",
    "steps = 'SMUS'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d330c5796d67fb1",
   "metadata": {},
   "source": [
    "# Prompt user for username and print confirmation\n",
    "username = input(\"Enter your username: \")\n",
    "if not username.strip():\n",
    "    print(\"Username is required!\")\n",
    "else:\n",
    "    print(f\"Username entered: {username}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "dd367042-c5f1-4602-94af-cd6d20797cae",
   "metadata": {},
   "source": [
    "# Warmup OF 5 Pairs\n",
    "Green indicates the cell that we want to explain.\\n\n",
    "Yellow indicates a filled cell that is used in the explanation\n",
    "Blue highligh one constraint (row, column, block) that is used for the explanation"
   ]
  },
  {
   "cell_type": "code",
   "id": "3883d457-2603-4813-8bd2-d2ff810e291f",
   "metadata": {},
   "source": [
    "sudokus = load_sudokus_from_json()\n",
    "\n",
    "steps_sudokus = []\n",
    "for index in range(15):\n",
    "    steps_single_sudoku = []\n",
    "    df_steps = pd.read_csv(f'data/gt_sudoku/SMUS/sudoku_user_SMUS_sudoku_{index}.csv',index_col=False)\n",
    "    for index, row in df_steps.iterrows():\n",
    "        grid = np.fromstring(row['grid'].replace(\"[\", \"\").replace(\"]\", \"\"), sep=\" \").astype(int).reshape(9, 9)\n",
    "        r,c = ast.literal_eval(row['hint_derived'])[1][:2]\n",
    "        steps_single_sudoku.append([grid,[r,c]])\n",
    "    steps_sudokus.append(steps_single_sudoku)\n",
    "\n",
    "\n",
    "oracle = Human()\n",
    "output_location_machop = f'results/warmup'\n",
    "output_location_baseline = f'results/warmup/'\n",
    "user = 0\n",
    "df_steps_evaluation = ''\n",
    "initial_weights = dict.fromkeys(OBJECTIVES_SUDOKU, 1)\n",
    "\n",
    "\n",
    "pef = PreferenceElicitationFramework(logic_puzzles_set=sudokus[5:], oracle=oracle, no_oracle=user,\n",
    "                                     initial_weights=initial_weights, instance_evaluation=sudokus[30],\n",
    "                                     df_steps_evaluation=df_steps_evaluation, output_location=output_location_machop,\n",
    "                                     time_eval=150,max_data=5,\n",
    "                                     normalized=normalization, batch_size=1, frozen_steps=steps_sudokus[5:],\n",
    "                                     lr=lr, type_diversification='MACHOP',exploration_root=1/2)\n",
    "learned_weights  = pef.start()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "acc8eb29-ba25-4663-af2f-84d3626c8334",
   "metadata": {},
   "source": [
    "# Start Real Experiment\n",
    "## Training by labelling 50 pairs"
   ]
  },
  {
   "cell_type": "code",
   "id": "9ca833711a2700b6",
   "metadata": {},
   "source": [
    "# Reload sudoku puzzles and prepare steps for real experiment\n",
    "sudokus = load_sudokus_from_json()\n",
    "\n",
    "steps_sudokus = []\n",
    "for index in range(15):\n",
    "    steps_single_sudoku = []\n",
    "    # Read ground truth steps for each sudoku from CSV\n",
    "    df_steps = pd.read_csv(f'data/gt_sudoku/SMUS/sudoku_user_SMUS_sudoku_{index}.csv',index_col=False)\n",
    "    for index, row in df_steps.iterrows():\n",
    "        # Parse grid and hint coordinates from CSV row\n",
    "        grid = np.fromstring(row['grid'].replace(\"[\", \"\").replace(\"]\", \"\"), sep=\" \").astype(int).reshape(9, 9)\n",
    "        r,c = ast.literal_eval(row['hint_derived'])[1][:2]\n",
    "        steps_single_sudoku.append([grid,[r,c]])\n",
    "    steps_sudokus.append(steps_single_sudoku)\n",
    "\n",
    "# Set initial weights and output locations for real experiment\n",
    "weights = dict.fromkeys(OBJECTIVES_SUDOKU, 1)\n",
    "\n",
    "oracle = Human()\n",
    "output_location_machop = f'results_AAAI/sudoku/real_case_{username}_{lr}_MACHOP/'\n",
    "output_location_baseline = f'results_AAAI/sudoku/real_case_{username}_{lr}_baseline/'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training by labelling 50 pairs ",
   "id": "0c4555d2-d49c-476f-976f-1eff054b1a57"
  },
  {
   "cell_type": "code",
   "id": "d23ede95-d857-41a2-a3dc-9145b9e2fc8a",
   "metadata": {},
   "source": [
    "# Run preference elicitation framework for baseline strategy (50 pairs)\n",
    "user = 0\n",
    "df_steps_evaluation = ''\n",
    "initial_weights = dict.fromkeys(OBJECTIVES_SUDOKU, 1)\n",
    "pef = PreferenceElicitationFramework(logic_puzzles_set=sudokus, oracle=oracle, no_oracle=user,\n",
    "                                     initial_weights=initial_weights, instance_evaluation=sudokus[30],\n",
    "                                     df_steps_evaluation=df_steps_evaluation, output_location=output_location_baseline,\n",
    "                                     time_eval=150,max_data=50,\n",
    "                                     normalized=normalization, batch_size=1, frozen_steps=steps_sudokus,\n",
    "                                     lr=lr, type_diversification='baseline', exploration_root=1)\n",
    "learned_weights  = pef.start()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fe1a7a02-3d69-4e2b-ae75-ccd634a504da",
   "metadata": {},
   "source": [
    "# Function to retrieve weights and normalization values for a given step\n",
    "def get_weights_norm_steps(step):\n",
    "    # Read weights and normalization for MACHOP strategy\n",
    "    df_weights_machop = pd.read_csv(f'{output_location_machop}weights.csv')\n",
    "    df_norm_machop = pd.read_csv(f'{output_location_machop}norm.csv')\n",
    "\n",
    "    weights_column = df_weights_machop['weights']\n",
    "    last_value_str = weights_column.iloc[step-1]\n",
    "    weights_machop = ast.literal_eval(last_value_str)\n",
    "\n",
    "    weights_column = df_norm_machop['norm']\n",
    "    last_value_str = weights_column.iloc[step-1]\n",
    "    norm_machop = ast.literal_eval(last_value_str)\n",
    "\n",
    "    # Read weights and normalization for baseline strategy\n",
    "    df_weights_baseline = pd.read_csv(f'{output_location_baseline}weights.csv')\n",
    "    df_norm_baseline = pd.read_csv(f'{output_location_baseline}norm.csv')\n",
    "\n",
    "    weights_column = df_weights_baseline['weights']\n",
    "    last_value_str = weights_column.iloc[step-1]\n",
    "    weights_baseline = ast.literal_eval(last_value_str)\n",
    "\n",
    "    weights_column = df_norm_baseline['norm']\n",
    "    last_value_str = weights_column.iloc[step-1]\n",
    "    norm_baseline = ast.literal_eval(last_value_str)\n",
    "\n",
    "    return weights_machop,norm_machop,weights_baseline,norm_baseline"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "060c8c64-8f3a-412e-a2ea-096209c2a011",
   "metadata": {},
   "source": [
    "# Evaluation - Generation of the steps"
   ]
  },
  {
   "cell_type": "code",
   "id": "e7ee185a-54be-4f91-a055-91a6f2da1a39",
   "metadata": {},
   "source": [
    "# Generate predicted steps using MACHOP weights for steps 10, 30, 50\n",
    "for step in [10,30,50]:\n",
    "    weights_machop,norm_machop,weights_baseline,norm_baseline = get_weights_norm_steps(step)\n",
    "    df_steps_evaluation = pd.read_csv('data/gt_sudoku/sudoku_gt_SMUS_sudoku_30.csv')\n",
    "    predicted = []\n",
    "    for index, row in tqdm(df_steps_evaluation.iterrows(), total=len(df_steps_evaluation)):\n",
    "        # Prepare sudoku grid and hint for evaluation\n",
    "        sudoku_eval = row['grid'].replace(' ', ', ')\n",
    "        sudoku_eval = np.array(eval(sudoku_eval))\n",
    "        parsed_list = eval(row['hint_derived'])\n",
    "        explained_row = parsed_list[1][0]\n",
    "        explained_col = parsed_list[1][1]\n",
    "        # Generate explanation using learnt MACHOP weights\n",
    "        exp,_,_ = generate_steps_sudoku(to_return=True, grid=sudoku_eval,\n",
    "                                        feature_weights=weights_machop,no_user=1,\n",
    "                                        sequential_sudoku=-1,normalization=norm_machop,\n",
    "                                        is_tqdm=False)\n",
    "        predicted.append(exp)\n",
    "\n",
    "    # Save predicted steps to CSV\n",
    "    df_predicted_steps = pd.DataFrame(predicted)\n",
    "    df_predicted_steps.to_csv(f'results_AAAI/sudoku/real_case_{username}_{lr}_MACHOP/machop_SMUS_{step}.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "37136ada-acd1-4de5-80b0-8aa580314355",
   "metadata": {},
   "source": [
    "# Generate predicted steps using baseline weights for steps 10, 30, 50\n",
    "for step in [10,30,50]:\n",
    "    weights_machop,norm_machop,weights_baseline,norm_baseline = get_weights_norm_steps(step)\n",
    "    df_steps_evaluation = pd.read_csv('data/gt_sudoku/sudoku_gt_SMUS_sudoku_30.csv')\n",
    "    predicted = []\n",
    "    for index, row in tqdm(df_steps_evaluation.iterrows(), total=len(df_steps_evaluation)):\n",
    "        # Prepare sudoku grid and hint for evaluation\n",
    "        sudoku_eval = row['grid'].replace(' ', ', ')\n",
    "        sudoku_eval = np.array(eval(sudoku_eval))\n",
    "        parsed_list = eval(row['hint_derived'])\n",
    "        explained_row = parsed_list[1][0]\n",
    "        explained_col = parsed_list[1][1]\n",
    "        # Generate explanation using learnt baseline weights\n",
    "        exp,_,_ = generate_steps_sudoku(to_return=True, grid=sudoku_eval,\n",
    "                                        feature_weights=weights_baseline,no_user=1,\n",
    "                                        sequential_sudoku=-1,normalization=norm_baseline,\n",
    "                                        is_tqdm=False)\n",
    "        predicted.append(exp)\n",
    "\n",
    "    # Save predicted steps to CSV\n",
    "    df_predicted_steps = pd.DataFrame(predicted)\n",
    "    df_predicted_steps.to_csv(f'results_AAAI/sudoku/real_case_{username}_{lr}_baseline/baseline_SMUS_{step}.csv', index=False)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "63bf0a84-be0c-4406-b18e-a2c2db8a8c14",
   "metadata": {},
   "source": [
    "# Load ground truth and predicted steps for evaluation and comparison\n",
    "dict_df = {}\n",
    "for step in [10,30,50]:\n",
    "    df_smus = pd.read_csv('data/gt_sudoku/sudoku_gt_SMUS_sudoku_30.csv')\n",
    "    df_learnt_baseline = pd.read_csv(f'results_AAAI/sudoku/real_case_{username}_{lr}_baseline/baseline_SMUS_{step}.csv')\n",
    "    df_learnt_machop = pd.read_csv(f'results_AAAI/sudoku/real_case_{username}_{lr}_MACHOP/machop_SMUS_{step}.csv')\n",
    "    dict_df[step] = [df_smus, df_learnt_baseline, df_learnt_machop]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e5a116a4-accf-463f-a051-7341f17e6fa1",
   "metadata": {},
   "source": [
    "# Compare learnt preferences (MACHOP) with SES by labelling and saving results\n",
    "for step in [10,30,50]:\n",
    "    df_smus,df_learnt_baseline,df_learnt_machop = dict_df[step]\n",
    "    # Remove matching hints and get cleaned dataframes\n",
    "    ties, df_smus_cleaned, df_learnt_machop_cleaned = count_and_remove_matching_hints(df_smus.copy(), df_learnt_machop.copy())\n",
    "    res = [df_smus_cleaned,df_learnt_machop_cleaned]\n",
    "    df_hand, df_learnt = res\n",
    "\n",
    "    # Shuffle rows for unbiased labelling\n",
    "    shuffled_indices = np.random.permutation(len(df_hand))\n",
    "    df_hand_shuffled = df_hand.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    df_learnt_shuffled = df_learnt.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    res_shuffled = [df_hand_shuffled, df_learnt_shuffled]\n",
    "\n",
    "    # Label explanations using Human oracle\n",
    "    oracle = Human()\n",
    "    res = oracle.label(res_shuffled,evaluation=True)\n",
    "    res['identical'] = ties\n",
    "    create_folders(f'results_AAAI/sudoku/real_case_{username}/')\n",
    "    # Save labelling results to JSON\n",
    "    with open(f'results_AAAI/sudoku/real_case_{username}/SMUS_machop_{step}.json', \"w\") as json_file:\n",
    "        json.dump(res, json_file, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbb64ec81c5028d1",
   "metadata": {},
   "source": [
    "# Compare learnt preferences (baseline) with SES by labelling and saving results\n",
    "for step in [10,30,50]:\n",
    "    df_smus,df_learnt_baseline,df_learnt_machop = dict_df[step]\n",
    "    # Remove matching hints and get cleaned dataframes\n",
    "    ties, df_smus_cleaned, df_learnt_baseline_cleaned = count_and_remove_matching_hints(df_smus.copy(), df_learnt_baseline.copy())\n",
    "    res = [df_smus_cleaned,df_learnt_baseline_cleaned]\n",
    "    df_hand, df_learnt = res\n",
    "\n",
    "    # Shuffle rows for unbiased labelling\n",
    "    shuffled_indices = np.random.permutation(len(df_hand))\n",
    "    df_hand_shuffled = df_hand.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    df_learnt_shuffled = df_learnt.iloc[shuffled_indices].reset_index(drop=True)\n",
    "    res_shuffled = [df_hand_shuffled, df_learnt_shuffled]\n",
    "\n",
    "    # Label explanations using Human oracle\n",
    "    oracle = Human()\n",
    "    res = oracle.label(res_shuffled,evaluation=True)\n",
    "    res['identical'] = ties\n",
    "    create_folders(f'results_AAAI/sudoku/real_case_{username}/')\n",
    "    # Save labelling results to JSON\n",
    "    with open(f'results_AAAI/sudoku/real_case_{username}/SMUS_baseline_{step}.json', \"w\") as json_file:\n",
    "        json.dump(res, json_file, indent=4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "150012571d11ddfb",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "62462816-7c8b-4e2e-855d-4a8d8e71e043",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "6085e179-f535-4cb4-9c54-17a2281add1e",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
